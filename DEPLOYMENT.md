# üöÄ Wurm-Ki Deployment Guide f√ºr Coolify

Diese Anleitung erkl√§rt Schritt f√ºr Schritt, wie du Wurm-Ki mit Coolify und Docker deployest.

## üìã Voraussetzungen

1. **Coolify Server** (installiert und l√§uft)
   - Mindestens 2GB RAM
   - 20GB freier Speicherplatz
   - Domain/Subdomain (z.B. `wurm-ki.yourdomain.com`)

2. **Ollama Server** (f√ºr LLM Models)
   - Kann auf demselben oder einem separaten Server laufen
   - Installation: https://ollama.ai/download

3. **Git Repository**
   - Dieser Code muss in einem Git-Repository sein (GitHub/GitLab/Gitea)

---

## üéØ Option 1: Deployment via Coolify (Empfohlen)

### Schritt 1: Repository vorbereiten

1. **Code ins Git-Repository pushen:**
   ```bash
   cd /home/ruben/open-webui
   git add .
   git commit -m "Prepare Wurm-Ki for deployment"
   git push origin main
   ```

2. **Wichtig:** Stelle sicher, dass diese Dateien im Repository sind:
   - ‚úÖ `Dockerfile`
   - ‚úÖ `docker-compose.yml`
   - ‚úÖ `.dockerignore`
   - ‚úÖ `.env.production` (als Template)

### Schritt 2: Coolify Projekt erstellen

1. **In Coolify einloggen**
   - √ñffne dein Coolify Dashboard

2. **Neues Projekt erstellen:**
   - Klicke auf "New Project"
   - Name: `wurm-ki`
   - Optional: Environment w√§hlen (Production)

3. **Neue Ressource hinzuf√ºgen:**
   - W√§hle "New Resource"
   - Typ: **"Docker Compose"** oder **"Dockerfile"**

### Schritt 3: Git-Repository verbinden

1. **Source ausw√§hlen:**
   - W√§hle deine Git-Quelle (GitHub/GitLab/Gitea)
   - Repository: Dein Wurm-Ki Repository
   - Branch: `main` (oder dein Deployment-Branch)

2. **Build-Konfiguration:**
   - Dockerfile Path: `./Dockerfile` (Standard)
   - Docker Compose: Wenn du docker-compose nutzen willst: `./docker-compose.yml`

### Schritt 4: Environment Variables konfigurieren

F√ºge diese Environment Variables in Coolify hinzu:

**Wichtige Variablen:**
```bash
# 1. SECURITY (KRITISCH!)
WEBUI_SECRET_KEY=<generiere-einen-random-string>
# Generieren: python -c "import secrets; print(secrets.token_hex(32))"

# 2. OLLAMA VERBINDUNG
OLLAMA_BASE_URL=http://host.docker.internal:11434
# Wenn Ollama auf anderem Server: http://OLLAMA_SERVER_IP:11434

# 3. AUTHENTICATION
ENABLE_SIGNUP=false
ENABLE_LOGIN_FORM=true
DEFAULT_USER_ROLE=user

# 4. PRIVACY
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false

# 5. NETWORKING
CORS_ALLOW_ORIGIN=*
FORWARDED_ALLOW_IPS=*
```

**Optional (wenn du OpenAI nutzen willst):**
```bash
OPENAI_API_KEY=sk-...
OPENAI_API_BASE_URL=https://api.openai.com/v1
```

### Schritt 5: Domain konfigurieren

1. **Domain hinzuf√ºgen:**
   - In Coolify unter "Domains"
   - F√ºge deine Domain hinzu: `wurm-ki.yourdomain.com`
   - SSL wird automatisch via Let's Encrypt eingerichtet

2. **Port Mapping:**
   - Container Port: `8080` (Standard von Wurm-Ki)
   - Public Port: `80` oder `443` (Coolify managed das automatisch)

### Schritt 6: Volume/Storage konfigurieren

**Wichtig:** Persistente Daten speichern!

1. **Volume hinzuf√ºgen:**
   - Path im Container: `/app/backend/data`
   - Host Path: `/var/lib/coolify/volumes/wurm-ki-data`

2. **Datenbank & Uploads:**
   - SQLite DB wird in `/app/backend/data` gespeichert
   - User-Uploads werden in `/app/backend/data/uploads` gespeichert

### Schritt 7: Deployment starten

1. **Deploy Button klicken** üöÄ
2. **Build-Log beobachten:**
   - Der Build dauert ca. 5-10 Minuten beim ersten Mal
   - Frontend wird mit Node.js gebaut
   - Backend Python-Dependencies werden installiert

3. **Status pr√ºfen:**
   - Wenn "Running" ‚Üí Deployment erfolgreich! ‚úÖ

### Schritt 8: Ersten Admin-User erstellen

1. **Beim ersten Start:**
   - √ñffne `https://wurm-ki.yourdomain.com`
   - Das System erkennt, dass keine Users existieren
   - Du kannst den ersten Admin-Account erstellen

2. **Wichtig:** Nach dem ersten Admin-Login:
   - Gehe zu Admin Panel
   - Erstelle weitere User-Accounts (Signup ist deaktiviert)

---

## üéØ Option 2: Lokales Testing mit Docker Compose

Vor dem Production-Deployment kannst du lokal testen:

### 1. Environment File erstellen

```bash
cd /home/ruben/open-webui
cp .env.production .env
```

Editiere `.env` und setze die Werte:
```bash
nano .env
```

### 2. Docker Compose starten

```bash
# Build und Start
docker-compose up -d

# Logs ansehen
docker-compose logs -f

# Stoppen
docker-compose down
```

### 3. Testen

√ñffne: `http://localhost:3000`

---

## üîß Ollama Setup

### Option A: Ollama auf demselben Server

```bash
# Ollama installieren
curl -fsSL https://ollama.com/install.sh | sh

# Model herunterladen (z.B. Llama 3.2)
ollama pull llama3.2

# Ollama l√§uft automatisch auf Port 11434
# In Wurm-Ki: OLLAMA_BASE_URL=http://host.docker.internal:11434
```

### Option B: Ollama auf separatem Server

```bash
# Auf dem Ollama-Server
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2

# Ollama f√ºr externe Verbindungen √∂ffnen
# /etc/systemd/system/ollama.service
OLLAMA_HOST=0.0.0.0:11434

# In Wurm-Ki: OLLAMA_BASE_URL=http://OLLAMA_SERVER_IP:11434
```

---

## üìä Monitoring & Logs

### In Coolify:

1. **Logs ansehen:**
   - Coolify Dashboard ‚Üí Dein Service ‚Üí Logs
   - Real-time Logs verf√ºgbar

2. **Metriken:**
   - CPU, RAM, Network Usage
   - Container Health Status

### Via Docker:

```bash
# Container Logs
docker logs wurm-ki -f

# Container Status
docker ps | grep wurm-ki

# Container inspizieren
docker inspect wurm-ki
```

---

## üîí Sicherheits-Checkliste

- [ ] `WEBUI_SECRET_KEY` ist ein zuf√§lliger String (nicht "changeme")
- [ ] `ENABLE_SIGNUP=false` (nur Admins k√∂nnen Users erstellen)
- [ ] SSL/HTTPS ist aktiviert (via Coolify Let's Encrypt)
- [ ] Firewall erlaubt nur Port 80/443
- [ ] Backups sind konfiguriert (siehe unten)
- [ ] Strong Passwords f√ºr Admin-Accounts

---

## üíæ Backup & Restore

### Backup erstellen:

```bash
# Volume-Backup (Datenbank + Uploads)
docker run --rm \
  -v wurm-data:/data \
  -v $(pwd):/backup \
  alpine tar czf /backup/wurm-ki-backup-$(date +%Y%m%d).tar.gz -C /data .
```

### Restore:

```bash
# Backup wiederherstellen
docker run --rm \
  -v wurm-data:/data \
  -v $(pwd):/backup \
  alpine tar xzf /backup/wurm-ki-backup-YYYYMMDD.tar.gz -C /data
```

### Automatisches Backup (Cronjob):

```bash
# Crontab editieren
crontab -e

# T√§glich um 2 Uhr nachts Backup
0 2 * * * cd /var/backups && docker run --rm -v wurm-data:/data -v $(pwd):/backup alpine tar czf /backup/wurm-ki-backup-$(date +\%Y\%m\%d).tar.gz -C /data .
```

---

## üîÑ Updates deployen

### Via Coolify:

1. **Code √§ndern und pushen:**
   ```bash
   git add .
   git commit -m "Update XYZ"
   git push origin main
   ```

2. **In Coolify:**
   - Gehe zu deinem Service
   - Klicke "Redeploy"
   - Coolify pullt neuen Code und baut neu

### Manuell:

```bash
# Repository pullen
cd /home/ruben/open-webui
git pull

# Docker Image neu bauen
docker-compose build --no-cache

# Container neu starten
docker-compose down
docker-compose up -d
```

---

## üêõ Troubleshooting

### Problem: "Cannot connect to Ollama"

**L√∂sung:**
```bash
# 1. Pr√ºfe ob Ollama l√§uft
curl http://localhost:11434/api/version

# 2. Pr√ºfe OLLAMA_BASE_URL in Environment
docker inspect wurm-ki | grep OLLAMA_BASE_URL

# 3. Wenn auf anderem Server: Firewall pr√ºfen
telnet OLLAMA_SERVER_IP 11434
```

### Problem: "Build Failed"

**L√∂sung:**
```bash
# 1. Logs checken
docker-compose logs

# 2. Cache l√∂schen und neu bauen
docker-compose build --no-cache

# 3. Speicherplatz pr√ºfen
df -h
```

### Problem: "Cannot create admin user"

**L√∂sung:**
```bash
# 1. Container logs pr√ºfen
docker logs wurm-ki

# 2. Datenbank-Volume pr√ºfen
docker volume inspect wurm-data

# 3. Notfall: Volume l√∂schen und neu starten
docker-compose down -v
docker-compose up -d
```

---

## üìû Support & Hilfe

- **Open WebUI Docs:** https://docs.openwebui.com
- **Coolify Docs:** https://coolify.io/docs
- **Ollama Docs:** https://ollama.ai/docs

---

## üéâ Fertig!

Deine Wurm-Ki Instanz sollte jetzt laufen! üöÄ

**Wichtige URLs:**
- Wurm-Ki: `https://wurm-ki.yourdomain.com`
- Coolify Dashboard: `https://coolify.yourdomain.com`
- Ollama API: `http://your-server:11434`

**N√§chste Schritte:**
1. ‚úÖ Admin-Account erstellen
2. ‚úÖ User-Accounts f√ºr Team erstellen
3. ‚úÖ Modelle in Ollama laden (`ollama pull llama3.2`)
4. ‚úÖ Backup-Strategie testen
5. ‚úÖ Team einladen und schulen
